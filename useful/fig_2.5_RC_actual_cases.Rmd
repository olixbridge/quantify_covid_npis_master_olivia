---
title: "oliv_richardlucy"
output: html_document
---
```{r}
# install.packages("anytime")
# install.packages("plyr")
library(anytime) 
library(dplyr)
library(ggplot2)
library(gridExtra)
library(plyr)
library(EpiEstim)
library(zoo)
library(scales)
```

```{r}
data <- data.table::fread("/Users/oliviashi/Documents/MASTER_RESEARCH/data/ca.csv")
data$date <- as.Date(data$date,'%d-%m-%Y')
d <- data %>% filter(prname=="Quebec")
n=488
# Main algorithm
T.t <- length(d$casesSmooth)

f.od <- function(x) dgamma(x, shape = 40, rate = 2)   # mean = 20 days, sd = 10 days      
f.io <- function(y) dgamma(y, shape = 6.5^2/2.6, rate = 6.5/2.6)   # mean = 6.5 days, sd = 2.6 days
# convolution integral
f.id <- function(z) integrate(function(y,z) f.od(z-y)*f.io(y),-Inf,Inf,z)$value
f.id <- Vectorize(f.id) 

#plot(seq(0.01, 50, 0.01), f.id(seq(0.01, 50, 0.01)), type = 'l', xlab = "Delay (days)", ylab = "Density")

# Next, we perform a discrete approximation to the distribution of $T_{id}$ and compute the probability vector for
# \[ \theta_t = Pr[T_{id} = t] \quad t = 1, \dots, 45 \]
p.id <- function(q) integrate(f.id, 0, q)$value
p.id <- Vectorize(p.id)
#p.id(Inf)

pr.id <- diff(p.id(0:45))
#plot(pr.id, xlim = c(0, 45), xlab = "Delay (days)", ylab = "Probability")
#sum(pr.id)
pr.id <- pr.id / sum(pr.id)


# Delay distribution
T.t <- length(d$cases)
pr.id
T.id <- length(pr.id)
pr.id.mat <- matrix(0, nrow = T.t, ncol = T.t+T.id-1)
for (j in 1:T.t) {
  pr.id.mat[j, j:(j+T.id-1)] <- rev(pr.id)
}

q <- colSums(pr.id.mat)
summary(q)


# EM algorithm
D <- d$deaths
N0 <- length(D)
lambda <- rep(2, T.t+T.id-1)
lambda[20:(20+T.t-1)] <- D

p.mat <- pr.id.mat
chi2 <- c()
for (ite in 1:100) {
  lambda.hat <- lambda * q
  #D.exp <- phat.mat %*% lambda.hat
  D.exp <- p.mat %*% lambda
  chi2[ite] <- 1/N0 * sum((D.exp - D)^2 / D.exp)
  if (chi2[ite] < 1) {
    return(lambda)
    print(ite)
  }
  else {
    lambda <- lambda / q * t(p.mat) %*% (D / D.exp)
  }
}

d$lambda <- lambda[1:488]
```


```{r}

x=seq(1, 10, by = 1)
si<-dnorm(x, mean = 5.2, sd = 1.7)
dfsi<-data.frame(date=seq(1, 10, by = 1),si=si)

#average growth rate
gr=(log(d$cases[12])-log(d$cases[1]))/12

# first we generate a "synthetic" incidence curve with a constant initial growth rate to approximate the deconvolved Philadel- phia incidence
```


```{r}
ir=seq(1,n,1)
actual_cases=seq(1,n,1)
for(t in 1:23){
  actual_cases[t]<-d$cases[t]
}

for(t in 20:488){
  denominator=1
  for(i in 1:t-1){
    if(t-i<10){denominator=denominator+d$cases[i]*si[t-i]}
  }
  ir[t]<-d$cases[t]/denominator
  adde=1
  i=1
  for(i in 1:10){
    cur=(actual_cases[t-i]*si[i])
    adde=adde+cur
  }
  
  # print(add)
  actual_cases[t]<-ir[t]*adde
}
# plot(x=seq(1,n,1),y=ir)
# plot(x=seq(1,n,1),y=actual_cases)
# plot(x=seq(1,n,1),y=d$cases)
df<-data.frame(date=d$date,actual_cases=actual_cases,reported_cases=d$cases)
```

```{r}
df<-df%>%filter(date<'2021-07-01')
fig_si<-ggplot(data=dfsi,aes(x=date,y=si))+geom_point() +geom_line()+ ggtitle("Infectiousness profile (serial interval) distribution for Covid") +ylab("proportion of total infectiousness") + xlab("time after infection (in days)")+theme(axis.text=element_text(size=8),axis.title=element_text(size=8))

fig2<-ggplot(data=df,aes(x=date))+geom_line(aes(y=actual_cases,col="actual_cases"))+geom_line(aes(y=reported_cases,col="reported_cases"))+ggtitle("Actual vs. reported cases by Richard-Lucy Deconvolution")+theme(axis.text=element_text(size=8),,axis.title=element_text(size=8),legend.position = c(0.8, 0.8)) +ylab("daily incidence")+scale_x_date(breaks = "2 months", date_labels = "%b %Y")+
  theme(legend.position = c(0.9, 0.8),legend.title = element_text(size = 5),legend.text = element_text(size = 5),legend.key.size=unit(0.5,"lines"),legend.key = element_blank())

ggarrange(fig_si,fig2,labels = c("A","B"),nrow=2)
```



```{r}
# ---- Smoothing the lambda ----
getLOESSCases <- function(dates, count_data, days_incl = 21, degree = 1,
                          truncation = 0) {
  if (truncation != 0) {
    dates <- dates[1:(length(dates) - truncation)]
    count_data <- count_data[1:(length(count_data) - truncation)]
  }
  n_points <- length(unique(dates))
  sel_span <- days_incl / n_points
  n_pad <- round(length(count_data) * sel_span * 0.5)
  c_data <- data.frame(value = c(rep(0, n_pad), count_data),
                       date_num = c(seq(as.numeric(dates[1]) - n_pad, as.numeric(dates[1]) - 1),
                                    as.numeric(dates)))
  c_data.lo <- loess(value ~ date_num, data = c_data, span = sel_span, degree = degree)
  smoothed <- predict(c_data.lo)
  smoothed[smoothed < 0] <- 0
  raw_smoothed_counts <- smoothed[(n_pad + 1):length(smoothed)]
  normalized_smoothed_counts <- round(
    raw_smoothed_counts * sum(count_data, na.rm = T) / sum(raw_smoothed_counts, na.rm = T))
  if (truncation != 0) {
    normalized_smoothed_counts <- append(normalized_smoothed_counts, rep(NA, truncation))
  }
  return(normalized_smoothed_counts)
}
```

d$actualCases <- getCases(d$date,d$cases)
```{r}
#library(zoo) # moving averages  
d$lambdaRM <- d$lambda
d$lambdaRM <- rollmean(d$lambdaRM,14,fill=NA)
d$lambdaSmooth <- smooth(d$lambda)
d$lambdaLoess <- getLOESSCases(d$date,d$lambda)
fig_smooth_comparison<-ggplot(data=d,aes(x=date))+
  geom_line(aes(y=lambda,col="N/A")) +
  geom_line(aes(y=lambdaSmooth,col="Smooth()")) +
  geom_line(aes(y=lambdaLoess,col="Loess()")) +
  geom_line(aes(y=lambdaRM,col="rollmean()")) +
  ggtitle("Comparison between different smoothing methods") +
  labs(colour="Method") +
  theme(legend.position = c(0.9, 0.8)) +
  xlab("Date") +
  ylab("Lambda")

# plot 
d$smooth <- getLOESSCases(d$date,d$cases)
d$casesSmooth <- getLOESSCases(d$date,d$cases)

d$deathsSmooth <- getLOESSCases(d$date,d$deaths)
#fig1<-ggplot(data=d,aes(x=date,y=smooth))+geom_point()
d$lambda <- lambda[1:488]
d$lambdaSmooth <- getLOESSCases(d$date,d$lambda)

ggplot(data=d,aes(x=date))+
  geom_line(aes(y=lambda,col="lambda"))+geom_line(aes(y=lambdaSmooth,col="Smothed lambda")) +
  ggtitle("lambda vs. smoothed lambda")

i=1
for(i in 1:length(d$date)){
  if(d$cases[i]==0){
    d$cases[i]<-d$cases[i-1]
  }
  d$ifr[i] <-d$deathsSmooth[i]/d$casesSmooth[i]
  i=i+1
}


# d$ifr <- getLOESSCases(d$date,d$ifr)

i=1
for(i in 1:length(d$date)){
  d$trueInfection[i] <- d$lambdaSmooth[i]/(d$ifr[i])
  i=i+1
}
ggplot(data=d,aes(x=date,y=ifr))+geom_point()
ggplot(data=d,aes(x=date))+geom_line(aes(y=trueInfection,col="Smoothed Infection"))+geom_line(aes(y=cases,col="cases"))
#spike for the green is delayed -> to adjust it i have to use deconvolution filter
ggplot(data=d,aes(x=date)) + geom_line(aes(y=d$deathsSmooth,col="deathSmooth"))+ geom_line(aes(y=d$casesSmooth/36,col="casesSmooth"))
#infection to confirmation delay 
fig1<-ggplot(data=d,aes(x=date))+
  geom_line(aes(y=lambda,col="lambda"))+geom_line(aes(y=lambdaRM,col="lambda rollmean")) +
  ggtitle("lambda vs. smoothed lambda")+ theme(legend.position = c(0.8, 0.8))
fig2<-ggplot(data=d,aes(x=date)) + geom_line(aes(y=d$cases,col="Reported cases"))+ geom_line(aes(y=d$casesSmooth,col="Smoothed cases")) + ggtitle("Reported vs. smoothed cases")+theme(legend.position = c(0.8, 0.8))
ggarrange(fig1,fig2,nrow=2)
```









